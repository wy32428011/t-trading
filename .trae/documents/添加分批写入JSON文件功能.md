# 添加分批写入JSON文件功能

## 需求分析

用户希望将分析完成后的数据分批写入JSON文件，而不是一次写入所有结果。这有助于：
- 减少内存占用，避免一次性保存大量数据导致的内存不足问题
- 提高系统的可靠性，即使程序中断，已分析的结果也能保存
- 方便用户随时查看已分析的结果，不需要等待所有股票分析完成

## 实现方案

### 1. 修改save_results方法

- 添加分批写入功能，支持将结果分批写入JSON文件
- 添加`batch_size`参数，用于指定每批写入的股票数量
- 添加`append`参数，用于指定是否追加到现有文件
- 确保分批写入的JSON文件是一个有效的JSON数组

### 2. 修改analyze_multiple_stocks方法

- 在分析过程中分批保存结果，当分析结果达到`batch_size`时，调用`save_results`方法保存结果
- 确保最后一批结果也能被保存
- 添加`save_batch_size`参数，用于指定分批保存的批次大小

### 3. 修改main函数

- 添加命令行参数`--save-batch-size`，允许用户指定分批保存的批次大小
- 传递该参数给`analyze_multiple_stocks`方法

## 实施步骤

1. **第一步**：修改`save_results`方法，添加分批写入功能
2. **第二步**：修改`analyze_multiple_stocks`方法，添加分批保存结果的功能
3. **第三步**：修改`main`函数，添加命令行参数`--save-batch-size`
4. **第四步**：测试分批写入功能，确保正常工作

## 技术细节

### 分批写入JSON文件的实现

- 当首次写入时，创建一个新的JSON文件，写入`[`
- 当追加写入时，在文件末尾添加`,`和新的结果
- 当所有结果写入完成后，在文件末尾添加`]`
- 确保JSON文件的格式正确，能够被正确解析

### 分批保存结果的实现

- 在`analyze_multiple_stocks`方法中，维护一个临时结果列表
- 当临时结果列表的长度达到`save_batch_size`时，调用`save_results`方法保存结果
- 清空临时结果列表，继续分析剩余股票
- 当所有股票分析完成后，保存剩余的结果

## 预期效果

- 程序能够在分析过程中分批保存结果
- 用户可以通过命令行参数指定分批保存的批次大小
- 分批保存的JSON文件是一个有效的JSON数组
- 即使程序中断，已分析的结果也能保存

## 风险评估

- 分批写入JSON文件可能会导致文件格式错误，需要确保正确处理文件的开头、中间和结尾
- 频繁的文件写入可能会影响性能，需要合理设置`save_batch_size`参数
- 需要确保最后一批结果也能被保存，避免数据丢失

通过以上实现方案，预计能够满足用户的需求，实现分批写入JSON文件的功能。